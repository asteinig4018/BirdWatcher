{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "makeModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKWj0P1qg05BTFDafNYb8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asteinig4018/BirdWatcher/blob/master/makeModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a Model\n",
        "The purpose of this notebook is to create a TFlite model for Raspberry Pi to detect birds (ideally in an image and not individually). I'll try to use the Caltech set. "
      ],
      "metadata": {
        "id": "nav6FeeZa8l5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sx8jm9jwZzU2"
      },
      "outputs": [],
      "source": [
        "#in progress: gather requirements\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import PIL.Image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#idk check the version\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHuJf9edcB2p",
        "outputId": "f6e2cb0c-05b9-4986-986d-eaba40c40804"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Dataset"
      ],
      "metadata": {
        "id": "-BCQsbGlbnOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset:"
      ],
      "metadata": {
        "id": "9KFeFzYPbxvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#easy way but not compatible with yolo as far as I can tell\n",
        "# bird_train_data = tfds.load('caltech_birds2011', split='train', shuffle_files=True)\n",
        "# bird_test_data = tfds.load('caltech_birds2011', split='test', shuffle_files=False)"
      ],
      "metadata": {
        "id": "wQ0uIws4b1N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#physicall download\n",
        "!gdown https://drive.google.com/u/0/uc?id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fka4hYRQGYg9",
        "outputId": "caf1824e-cb7d-4748-9beb-7542faffd9e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45\n",
            "To: /content/CUB_200_2011.tgz\n",
            "100% 1.15G/1.15G [00:09<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /content/CUB_200_2011.tgz"
      ],
      "metadata": {
        "id": "QKct65ZPJasb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add some more image manipulation packages\n",
        "!pip install imagesize\n",
        "import imagesize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16481lzKDtUE",
        "outputId": "f846fa34-477e-49f8-db68-573d881cbe6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use a class to track data so we can create yolo specific data structures\n",
        "class Yolo_Image:\n",
        "\n",
        "  def __init__(self, filename, subdir):\n",
        "    self.bb = list()\n",
        "    self.classname = \"\"\n",
        "    self.filename = filename\n",
        "    self.subdir = subdir\n",
        "    #print(self.filename)\n",
        "    self.set_img_dim()\n",
        "    self.tt = 0\n",
        "\n",
        "  def add_bb(self, bx, by, w, h):\n",
        "    self.bb = [float(bx)/self.width, float(by)/self.height, \n",
        "               float(w)/self.width, float(h)/self.height]\n",
        "\n",
        "  def get_bb(self):\n",
        "    return self.bb\n",
        "\n",
        "  #get the 0 index class id\n",
        "  def add_class(self, classname):\n",
        "    self.classnum = int(classname) - 1\n",
        "\n",
        "  def get_class(self):\n",
        "    return self.classnum\n",
        "\n",
        "  def get_txt_filename(self):\n",
        "    return os.path.splitext(self.filename)[0] + \".txt\"\n",
        "\n",
        "  def get_jpg_filename(self):\n",
        "    return self.filename\n",
        "\n",
        "  #these we'll use to set whether they're part of the training or testing set\n",
        "  def set_type(self, t_or_t):\n",
        "    self.tt = int(t_or_t)\n",
        "    print(self.tt)\n",
        "\n",
        "  def get_type(self):\n",
        "    return self.tt\n",
        "\n",
        "  def set_img_dim(self):\n",
        "    self.width, self.height = imagesize.get(\"/content/CUB_200_2011/images/\" + self.subdir + \"/\" + self.filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "XAL3nuF9jcxn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create yolo classes for each image\n",
        "YImages = []\n",
        "lines = []\n",
        "with open('/content/CUB_200_2011/images.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "  YImages.append(Yolo_Image((line.split()[1]).split('/')[1], \n",
        "                 (line.split()[1]).split('/')[0]))\n",
        "\n",
        "#now that we have them all in order, let's add the classes\n",
        "with open('/content/CUB_200_2011/image_class_labels.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "indexer = 0\n",
        "for line in lines:\n",
        "  YImages[indexer].add_class(line.split()[1])\n",
        "  indexer+=1\n",
        "\n",
        "#get bounding boxes\n",
        "with open('/content/CUB_200_2011/bounding_boxes.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "indexer = 0\n",
        "for line in lines:\n",
        "  parts = line.split()\n",
        "  YImages[indexer].add_bb(parts[1], parts[2], parts[3], parts[4])\n",
        "  indexer+=1\n",
        "\n",
        "#get whether images should be in test or train dataset\n",
        "with open('/content/CUB_200_2011/train_test_split.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "indexer = 0\n",
        "for line in lines:\n",
        "  YImages[indexer].set_type(line.split()[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "mg-iIQQqm0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's organize the pictures and labels\n",
        "!mkdir /content/dataset-train\n",
        "!mkdir /content/dataset-test\n",
        "!mkdir /content/dataset-train/images\n",
        "!mkdir /content/dataset-train/labels\n",
        "!mkdir /content/dataset-test/images\n",
        "!mkdir /content/dataset-test/labels"
      ],
      "metadata": {
        "id": "bhGecara6M42"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/CUB_200_2011/images/**/*.jpg /content/dataset-train/images/"
      ],
      "metadata": {
        "id": "ido5mPGp6i8t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create label files and move testing data\n",
        "import shutil\n",
        "\n",
        "#need to create this folder\n",
        "LOCATION_PREFIX_TRAIN = \"/content/dataset-train/labels/\"\n",
        "LOCATION_PREFIX_TEST = \"/content/dataset-test/labels\"\n",
        "\n",
        "for yimg in YImages:\n",
        "  f = None\n",
        "  if yimg.get_type():\n",
        "    f = open(LOCATION_PREFIX_TRAIN + yimg.get_txt_filename(), 'w')\n",
        "  else:\n",
        "    #it is a testing image\n",
        "    f = open(LOCATION_PREFIX_TEST + yimg.get_txt_filename(), 'w')\n",
        "    #and let's move the corresponding image\n",
        "    shutil.move(LOCATION_PREFIX_TRAIN + yimg.get_jpg_filename(), \n",
        "                LOCATION_PREFIX_TEST + yimg.get_jpg_filename())\n",
        "    \n",
        "  f.write(str(yimg.get_class()) + \" \")\n",
        "  for x in yimg.get_bb():\n",
        "    f.write(str(x) + \" \")\n",
        "\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "WHXwDrkhrUl_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get all the class names\n",
        "lines = []\n",
        "with open('/content/CUB_200_2011/classes.txt','r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "classes = []\n",
        "for line in lines:\n",
        "  classes.append(line.split()[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "TYSNpKKvt1X3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the yaml\n",
        "f = open('/content/dataset.yaml', 'w')\n",
        "f.write(\"train: /content/dataset-train/images\\n\")\n",
        "f.write(\"val: /content/dataset-train/images\\n\")\n",
        "f.write(\"test: /content/dataset-test/images\\n\\n\")\n",
        "f.write(\"nc: \"+ str(len(classes)) + \"\\n\\n\")\n",
        "f.write(\"names: \" + str(classes) + \"\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "zPIBVtbNBHrO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get YOLOv5 ver 6 "
      ],
      "metadata": {
        "id": "ZG2dB_VMfzWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "import torch\n",
        "from IPython.display import Image, clear_output # for showing images"
      ],
      "metadata": {
        "id": "vuN_s7wUf4_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actually do the training:\n",
        "\n",
        "\n",
        "*   img = set our max image size which works even though we have variable image sizes (the unused part of the square is padded with gray\n",
        "*   batch = this depends on the gpu/architecture/how we want to train it\n",
        "*   epochs = how long we want to train it - longer is better up to a point\n",
        "*   data = point to the yaml above\n",
        "*   weights = which weights we want to start with\n",
        "*   cache = we can turn this on so it is faster but it will also take more RAM\n",
        "\n"
      ],
      "metadata": {
        "id": "4IFFB70_Gv5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python train.py --img 640 --batch 16 --epochs 25 --data /content/dataset.yaml --weights yolov5n.pt"
      ],
      "metadata": {
        "id": "dTwUMJthGzlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "PXokNSoXIQoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test\n",
        "Use our test dataset for this"
      ],
      "metadata": {
        "id": "LpH__rMPJi1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --data /content/daatset.yaml --weights TBD.pt"
      ],
      "metadata": {
        "id": "lj5398sGJ2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export \n",
        "Export the weights and network so we can use it on another device."
      ],
      "metadata": {
        "id": "2L5QpzirKAsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights TBD.pt --include tflight onnx --simplify"
      ],
      "metadata": {
        "id": "6rYadcxDKoYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}